[["index.html", "GOVT 8002 Shared Working Book Spring 2024 1 Introduction 1.1 Purpose of This Site 1.2 Loading Data", " GOVT 8002 Shared Working Book Spring 2024 Benjamin Reese | bfr11@georgetown.edu 1 Introduction 1.1 Purpose of This Site The goal of this site is to have a place where you can look for examples of code. Think of this site as a log of all of the topics we cover in class and in lab sessions. I will make updates throughout the semester as we cover more advanced material. I hope this proves to be a helpful and beneficial resource and offer an easier to access format than the files posted to Canvas. If you are interested, I am happy to add you to the GitHub and you can make some direct edits to add your code! Let me know if any of this code doesn’t run correctly or if you have any questions or issues! 1.2 Loading Data The easiest way to load data into R and ensure you have the correct file path is to create a folder on your computer for each assignment and place the datasets directly into that folder. Create a folder on your computer for each new analysis Download your Data and move the file to your newly created folder Then open RStudio Click the project button in the top right corner Click new project Click existing directory Click browse and find the folder that you created Click create project Once your new project opens, click the blank page with a green plus sign icon in the top left corner under the file option Click R script to open a new script You should also be able to see your data file in the bottom right window of RStudio, click the file and follow the options depending on the file type Once your data is imported into R, the code that R automatically ran will be in the console window on the bottom left, copy and paste it to your fresh R script For example, in Lab 1, my code looked like: read_excel(\"USstates.xlsx\") Run this copy and pasted line of code whenever you open the R Project and you will never have to worry about complicated file pathing commands I recommend using the assignment operator &lt;- to give your dataset a short and simple name like df, dta, or, if you are working with multiple datasets, name each something short and descriptive "],["lab-i-tidyverse.html", "2 Lab I: Tidyverse 2.1 Join the data sets. 2.2 Create and add the following four variables to your dataframe: density (based on sqMiles and pop2019), deaths per capita (based on new_death), cases per capita (based on new_case) and vaccinated percent (based on Series_Complete_12PlusPop_Pct). 2.3 Estimate three regression models with deaths per capita on your selected day as the dependent variable. 2.4 Assess specific vaccines", " 2 Lab I: Tidyverse 2.0.1 Preparation ## Packages library(tidyverse) library(dplyr) library(readxl) # Package to read Excel data library(stargazer) 2.1 Join the data sets. Join the cases and vaccination data by date and state. Case data: United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv Vaccination data: COVID-19_Vaccinations_in_the_United_States_Jurisdiction.csv Other state variables: USstates.xlsx Add the USstates.xlsx data and limit your dataframe to the states listed in USstates.xlsx. How do you know if your merge was successful? ANSWER: Looking at the dataframe is useful. Look at individual states - do the variables that are supposed to be the same (e.g. population) the same over the time period? Do the case numbers look reasonable? ## Load data # https://data.cdc.gov/Case-Surveillance/United-States-COVID-19-Cases-and-Deaths-by-State-o/9mfq-cb36 cases &lt;- read.csv(&quot;Data/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv&quot;) # Vax data # &quot;COVID-19 Vaccinations in the United States,Jurisdiction&quot; # https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc vax &lt;- read.csv(&quot;Data/COVID-19_Vaccinations_in_the_United_States_Jurisdiction.csv&quot;) df &lt;- cases %&gt;% left_join(vax, by = c(&quot;submission_date&quot; = &quot;Date&quot;, &quot;state&quot; = &quot;Location&quot;)) # Add state variables stFacts &lt;- read_excel(&quot;Data/USstates.xlsx&quot;, sheet = &quot;data&quot;) %&gt;% rename(trump2020Pct = trump2020_percent) # %&gt;% mutate(trump2020Pct = trump2020Pct) df &lt;- df %&gt;% filter(state %in% stFacts$stateAbbr == 1) %&gt;% left_join(stFacts, by = c(&quot;state&quot; = &quot;stateAbbr&quot;)) 2.2 Create and add the following four variables to your dataframe: density (based on sqMiles and pop2019), deaths per capita (based on new_death), cases per capita (based on new_case) and vaccinated percent (based on Series_Complete_12PlusPop_Pct). For a specific day (based on submission_date), show the top five states ranked by deaths per capita and calculate the average vaccinated per capita and the mean, minimum and maximum deaths per capita. df &lt;- df %&gt;% mutate(&quot;deathsPC&quot; = 100000*new_death/pop2019, &quot;casesPC&quot; = 100000*new_case/pop2019, &quot;vaxedPct&quot; = Series_Complete_12PlusPop_Pct/100, &quot;density&quot; = pop2019/(1000000*sqMiles)) # Pick a day DATE &lt;- &quot;10/18/2021&quot; df_day &lt;- df %&gt;% filter(submission_date == DATE) %&gt;% arrange(desc(deathsPC)) # Look at data (check for negative deaths etc) df_day %&gt;% dplyr::select(submission_date, state, new_case, new_death, deathsPC, casesPC) %&gt;% slice(1:5) ## submission_date state new_case new_death deathsPC casesPC ## 1 10/18/2021 ID 1290 42 2.350222 72.18540 ## 2 10/18/2021 AK 691 16 2.187152 94.45762 ## 3 10/18/2021 MT 426 19 1.777731 39.85860 ## 4 10/18/2021 AL 961 84 1.713172 19.59951 ## 5 10/18/2021 WV 689 26 1.450774 38.44551 df_day %&gt;% summarize(meanVaxedPct = mean(vaxedPct), meanDeath = mean(deathsPC), minDeath = min(deathsPC), maxDeath = max(deathsPC)) ## meanVaxedPct meanDeath minDeath maxDeath ## 1 0.6388235 0.4587514 0 2.350222 2.3 Estimate three regression models with deaths per capita on your selected day as the dependent variable. Your first model will have only Trump 2020 percent as an independent variable. Your second model will add vaccinated percent as an independent variable. Your third model will add density. Before you estimate the models, write down your expectations about what will happen in these models. ANSWER: See table below. The key idea here is omitted variable bias. If we only have Trump percent, then vaccination rates are omitted. For October 1st, 2021, the Trump variable becomes insignificant when vaccination rates are included. One complication, for which I suspect there is no clear answer, is whether vaccination rates are a post-treatment variable. What do you think? ## Models ols.1 &lt;- lm(deathsPC ~ trump2020Pct, data = df_day) summary(ols.1) ## ## Call: ## lm(formula = deathsPC ~ trump2020Pct, data = df_day) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.86967 -0.29350 -0.10922 0.09968 1.65723 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.5191 0.3150 -1.648 0.10578 ## trump2020Pct 1.9868 0.6222 3.193 0.00246 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5275 on 49 degrees of freedom ## Multiple R-squared: 0.1722, Adjusted R-squared: 0.1554 ## F-statistic: 10.2 on 1 and 49 DF, p-value: 0.00246 ols.2 &lt;- lm(deathsPC ~ trump2020Pct + vaxedPct, data = df_day) summary(ols.2) ## ## Call: ## lm(formula = deathsPC ~ trump2020Pct + vaxedPct, data = df_day) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.8504 -0.3075 -0.0117 0.1776 1.6685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.0291 0.7263 2.794 0.007463 ** ## trump2020Pct 0.2193 0.7212 0.304 0.762361 ## vaxedPct -2.6272 0.6913 -3.800 0.000408 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4673 on 48 degrees of freedom ## Multiple R-squared: 0.3637, Adjusted R-squared: 0.3372 ## F-statistic: 13.72 on 2 and 48 DF, p-value: 1.941e-05 ols.3 &lt;- lm(deathsPC ~ trump2020Pct + vaxedPct + density, data = df_day) summary(ols.3) ## ## Call: ## lm(formula = deathsPC ~ trump2020Pct + vaxedPct + density, data = df_day) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.83946 -0.30634 -0.01337 0.16991 1.66741 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1095 0.8901 2.370 0.021938 * ## trump2020Pct 0.1205 0.9562 0.126 0.900283 ## vaxedPct -2.6711 0.7506 -3.559 0.000865 *** ## density -8.7715 54.9523 -0.160 0.873864 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4721 on 47 degrees of freedom ## Multiple R-squared: 0.364, Adjusted R-squared: 0.3234 ## F-statistic: 8.968 on 3 and 47 DF, p-value: 8.334e-05 2.4 Assess specific vaccines Create and add vaccinated percent by state for each of the Pfizer, Modern and Janssen (which is Johnson and Johnson) vaccines. Use pop2019 for population Use Series_Complete_Moderna_18Plus, Series_Complete_Janssen_18Plus and Series_Complete_Pfizer_18Plus for the vaccination totals. Estimate a model in which deaths per capita is a function of all three vaccination rates. Explain what the results mean, especially in light of the results above for overall vaccination results. Explain how one would compare the efficacy of the individual vaccines (e.g., whether the Moderna vaccine works better than the Johnson and Johnson vaccine). ANSWER: The major issue here is multicollinearity. For October 1, 2021, the overall vaccination rate was statistically significant (see models 1 - 3 in the table) yet each of the different vaccines was insignificant (see model 4). The vaccines are multicollinear (which can be assessed with an auxilliary regression) so the loss of power is not terribly surprising. An F-test whether all the specific vaccine variables equal zero is reported for model 4 and, broadly consistent with the results in models 1 -3 we can say that we can reject the null that all individual vaccines have zero effect. To assess whether Moderna is better than Johnson and Johnson we would do an F-test where our restricted equation adds those two vaccines. If doing so causes a substantial reduction in fit we would reject the null that the effects of those two vaccines are equal. (And we would want to take such results with a grain of salt given endogeneity in which states have which vaccines.) df &lt;- df %&gt;% mutate(&quot;vaxedPctModerna&quot; = Series_Complete_Moderna_18Plus/(100*pop2019), &quot;vaxedPctJans&quot; = Series_Complete_Janssen_18Plus/(100*pop2019), &quot;vaxedPctPfizer&quot; = Series_Complete_Pfizer_18Plus/(100*pop2019)) df_day &lt;- df %&gt;% filter(submission_date == DATE) ols.4 &lt;- lm(deathsPC ~ vaxedPctJans + vaxedPctModerna + vaxedPctPfizer, data = df_day) summary(ols.4) ## ## Call: ## lm(formula = deathsPC ~ vaxedPctJans + vaxedPctModerna + vaxedPctPfizer, ## data = df_day) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.02398 -0.33730 -0.03042 0.16891 1.55666 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.3934 0.6526 3.667 0.000623 *** ## vaxedPctJans 469.8399 1077.0087 0.436 0.664656 ## vaxedPctModerna -156.1936 541.3745 -0.289 0.774223 ## vaxedPctPfizer -676.4798 305.1014 -2.217 0.031480 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5201 on 47 degrees of freedom ## Multiple R-squared: 0.2282, Adjusted R-squared: 0.1789 ## F-statistic: 4.632 on 3 and 47 DF, p-value: 0.006426 stargazer(ols.1, ols.2, ols.3, ols.4, type = &quot;html&quot;, # FOR PDF - the &quot;asis&quot; above makes it work keep.stat = c(&quot;n&quot;,&quot;ser&quot;, &quot;rsq&quot;, &quot;f&quot;), report = &quot;vcst&quot;, column.labels = c(&quot;Model 1&quot;, &quot;Model 2&quot;, &quot;Model 3&quot;, &quot;Model 4&quot;), digits = 3, dep.var.caption = &quot;&quot;, dep.var.labels.include = FALSE) Model 1 Model 2 Model 3 Model 4 (1) (2) (3) (4) trump2020Pct 1.987 0.219 0.120 (0.622) (0.721) (0.956) t = 3.193 t = 0.304 t = 0.126 vaxedPct -2.627 -2.671 (0.691) (0.751) t = -3.800 t = -3.559 density -8.772 (54.952) t = -0.160 vaxedPctJans 469.840 (1,077.009) t = 0.436 vaxedPctModerna -156.194 (541.375) t = -0.289 vaxedPctPfizer -676.480 (305.101) t = -2.217 Constant -0.519 2.029 2.110 2.393 (0.315) (0.726) (0.890) (0.653) t = -1.648 t = 2.794 t = 2.370 t = 3.667 Observations 51 51 51 51 R2 0.172 0.364 0.364 0.228 Residual Std. Error 0.528 (df = 49) 0.467 (df = 48) 0.472 (df = 47) 0.520 (df = 47) F Statistic 10.196*** (df = 1; 49) 13.717*** (df = 2; 48) 8.968*** (df = 3; 47) 4.632*** (df = 3; 47) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 "],["lab-ii-panel-data.html", "3 Lab II: Panel Data 3.1 Load the data from Oxford_Covid_data_US_latest.csv 3.2 Data Organization 3.3 Use the lag function in dplyr to create lagged variables for cases and deaths. Also create “difference” (e.g., dCases) that is the change in cases for each state by date. 3.4 Merge the above data frame to data in USstates.xlsx 3.5 Estimate a pooled model of total cases per capita as a function of state policy. Discuss. 3.6 Estimate a one-way fixed effect model where the fixed effect is state. (Note that state is indicated in a variable called RegionName.) Estimate using both LSDV and the de-meaned version in the plm package. Can you identify a source of bias? 3.7 Estimate a two-way fixed effect model where the fixed effects are state and date. Estimate using both LSDV and the de-meaned version in the plm package. Does this model address the source of bias identified earlier?", " 3 Lab II: Panel Data 3.0.1 Preparation # Load packages used in this session of R library(knitr) library(tidyverse) library(plm) library(readr) library(readxl) # Package to read Excel data opts_chunk$set(echo = TRUE) options(digits = 2) In this lab we will estimate standard panel data models on covid policy and cases/deaths in U.S. states. This is not a full-fledged analysis, but rather an initial exploration of the data that illustrates how fixed effects models work. 3.1 Load the data from Oxford_Covid_data_US_latest.csv Oxford provides data on covid deaths/cases and policy variables by day by state. For more background, see this data archive or this story that uses the data. We will use a variable called GovernmentResponseIndex. For details, see this. (And feel free to experiment with the other measures.) 3.2 Data Organization Load the Oxford_Covid_data_US_latest.csv data Limit it to U.S. states (CountryName == “United States) Create the following variables: RegionName, RegionCode, Date, GovernmentResponseIndex, ConfirmedCases and ConfirmedDeaths Add a variable to this data frame using the following code (this variable will help us when merging below) mutate(&quot;stAbbrev&quot; = str_replace_all(string = RegionCode, pattern = &quot;US_&quot;, replacement = &quot;&quot; )) Show the first three variables of the first three lines of this data frame. # Load and filter state stringency data stPolicy = read_csv(&quot;Data/Oxford_Covid_data_US_latest.csv&quot;) %&gt;% filter(CountryName == &quot;United States&quot; &amp; is.na(RegionName) == 0 &amp; RegionName != &quot;&quot; &amp; RegionCode != &quot;US_VI&quot;) %&gt;% dplyr::select(RegionName, RegionCode, Date, ContainmentHealthIndex, GovernmentResponseIndex, StringencyIndex, ConfirmedCases, ConfirmedDeaths) %&gt;% mutate(&quot;stAbbrev&quot; = str_replace_all(string = RegionCode, pattern = &quot;US_&quot;, replacement = &quot;&quot; )) ## Rows: 20724 Columns: 69 ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (25): CountryName, CountryCode, RegionName, RegionCode, Jurisdiction, C1_Notes, C2_Notes, C3_Notes, C4_Notes, C5_N... ## dbl (43): Date, C1_School closing, C1_Flag, C2_Workplace closing, C2_Flag, C3_Cancel public events, C3_Flag, C4_Restri... ## lgl (1): M1_Wildcard ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Show the first three variables of first three lines stPolicy[1:3, 1:3] ## # A tibble: 3 × 3 ## RegionName RegionCode Date ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Alaska US_AK 20200101 ## 2 Alaska US_AK 20200102 ## 3 Alaska US_AK 20200103 3.3 Use the lag function in dplyr to create lagged variables for cases and deaths. Also create “difference” (e.g., dCases) that is the change in cases for each state by date. See slide “Creating differenced data in R” in Topic 3 class slides. ## Create lagged value stPolicy = stPolicy %&gt;% group_by(RegionName) %&gt;% mutate(lagCases = dplyr::lag(ConfirmedCases, order_by = Date), dCases = ConfirmedCases - lagCases, lagDeaths = dplyr::lag(ConfirmedDeaths, order_by = Date), dDeaths = ConfirmedDeaths - lagDeaths) %&gt;% ungroup() 3.4 Merge the above data frame to data in USstates.xlsx Merge by state abbreviation Create per capita measures of change in deaths and cases (e.g. “deathsPC” = 10000*dDeaths/pop2019). Check your data by looking at level and lagged data for a given state for a few years. The lagged data should match up to the previous period observation. # Load excel data stFacts &lt;- read_excel(&quot;Data/USstates.xlsx&quot;, sheet = &quot;data&quot;) # Merge with data frame and create per capita data dfState &lt;- stPolicy %&gt;% left_join(stFacts, by = c(&quot;stAbbrev&quot; = &quot;stateAbbr&quot;)) %&gt;% mutate(&quot;deathsPC&quot; = 10000*dDeaths/pop2019, &quot;casesPC&quot; = 10000*dCases/pop2019) # Check data dfState %&gt;% filter(RegionName == &quot;California&quot;) %&gt;% dplyr::select(RegionName, Date, ConfirmedDeaths, lagDeaths, dDeaths, deathsPC) %&gt;% slice(245:248) ## # A tibble: 4 × 6 ## RegionName Date ConfirmedDeaths lagDeaths dDeaths deathsPC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 California 20200901 13150 13022 128 0.0324 ## 2 California 20200902 13317 13150 167 0.0423 ## 3 California 20200903 13493 13317 176 0.0445 ## 4 California 20200904 13638 13493 145 0.0367 3.5 Estimate a pooled model of total cases per capita as a function of state policy. Discuss. ols.1 = lm(casesPC ~ GovernmentResponseIndex, data = dfState) summary(ols.1) ## ## Call: ## lm(formula = casesPC ~ GovernmentResponseIndex, data = dfState) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.895 -1.676 -1.010 0.457 42.295 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.925015 0.053919 17.16 &lt;2e-16 *** ## GovernmentResponseIndex 0.025512 0.001128 22.63 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.95 on 18497 degrees of freedom ## (1442 observations deleted due to missingness) ## Multiple R-squared: 0.02693, Adjusted R-squared: 0.02688 ## F-statistic: 511.9 on 1 and 18497 DF, p-value: &lt; 2.2e-16 3.6 Estimate a one-way fixed effect model where the fixed effect is state. (Note that state is indicated in a variable called RegionName.) Estimate using both LSDV and the de-meaned version in the plm package. Can you identify a source of bias? fe.1 = lm(casesPC ~ GovernmentResponseIndex + factor(RegionName), data = dfState) #summary(fe.1) coefficients(summary(fe.1))[1:2,] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.93487083 0.155462286 6.01349 1.849930e-09 ## GovernmentResponseIndex 0.04020073 0.001193666 33.67837 2.326953e-241 fe.1plm = plm(casesPC ~ GovernmentResponseIndex, data = dfState, index = c(&quot;RegionName&quot;,&quot;Date&quot;), model=&quot;within&quot;) summary(fe.1plm) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = casesPC ~ GovernmentResponseIndex, data = dfState, ## model = &quot;within&quot;, index = c(&quot;RegionName&quot;, &quot;Date&quot;)) ## ## Unbalanced Panel: n = 51, T = 348-368, N = 18499 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -4.31258 -1.67085 -0.76393 0.51040 41.90019 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## GovernmentResponseIndex 0.0402007 0.0011937 33.678 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 158100 ## Residual Sum of Squares: 148940 ## R-Squared: 0.057924 ## Adj. R-Squared: 0.05532 ## F-statistic: 1134.23 on 1 and 18447 DF, p-value: &lt; 2.22e-16 3.7 Estimate a two-way fixed effect model where the fixed effects are state and date. Estimate using both LSDV and the de-meaned version in the plm package. Does this model address the source of bias identified earlier? fe.2 = lm(casesPC ~ GovernmentResponseIndex + factor(RegionName) + factor(Date), data = dfState) #summary(fe.2) # Show non-fixed effect coefficients coefficients(summary(fe.2))[1:2,] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.18910849 0.293599291 0.6441041 5.195161e-01 ## GovernmentResponseIndex -0.02309587 0.002596958 -8.8934323 6.472717e-19 fe.2plm = plm(casesPC ~ GovernmentResponseIndex, data = dfState, index = c(&quot;RegionName&quot;,&quot;Date&quot;), model=&quot;within&quot;, effect=&quot;twoways&quot;) summary(fe.2plm) ## Twoways effects Within Model ## ## Call: ## plm(formula = casesPC ~ GovernmentResponseIndex, data = dfState, ## effect = &quot;twoways&quot;, model = &quot;within&quot;, index = c(&quot;RegionName&quot;, ## &quot;Date&quot;)) ## ## Unbalanced Panel: n = 51, T = 348-368, N = 18499 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -8.01513 -0.74894 -0.16411 0.53141 38.62467 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## GovernmentResponseIndex -0.023096 0.002597 -8.8934 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 69875 ## Residual Sum of Squares: 69571 ## R-Squared: 0.0043556 ## Adj. R-Squared: -0.018663 ## F-statistic: 79.0931 on 1 and 18080 DF, p-value: &lt; 2.22e-16 3.7.1 This is an initial analysis. We would also want to think through whether it is useful to control for days of the week (there is a well-known pattern in reporting across days of the week) assess the data for outliers (e.g, min(dfState$casesPC, na.rm = TRUE)) consider a lagged dependent variable For more, read this "],["lab-iii-2sls-instrumental-variables.html", "4 Lab III: 2SLS &amp; Instrumental Variables 4.1 Estimate a basic OLS model with “Do others regard you as religious” as the dependent variable as a function of Hajj2006. Explain how there might be endogeneity. 4.2 Explain how the “success” variable may satisfy the conditions for a instrumental variable. 4.3 Estimate a 2SLS model Religious as a function of Hajj2006. 4.4 Show the first stage from the 2SLS model above. Explain the implications of the results. 4.5 Add covariates for age, literacy, urban, group size and gender to the 2SLS model Religious as a function of Hajj2006. What is different? Which variables are included in the first stage? 4.6 Run multiple 2SLS models with OssamaIncorrect, GovtForce, NatlInterest, Happy, GirlsSchool and JobsWomen variables as dependent variables. Use the list of covariates from earlier. If you want, try using a loop or lapply (but not necessary).", " 4 Lab III: 2SLS &amp; Instrumental Variables 4.0.1 Preparation ## Packages library(haven) ## Package to read Stata data library(ivreg) ## Package to run 2sls library(fixest) ## This package can also run 2SLS library(tidyverse) ## For tidyverse commands library(here) ## Importing Data ## Loading Data hajj_public &lt;- read_dta(here(&quot;Data&quot;, &quot;hajj_public.dta&quot;)) Do important life experiences influence political and social views? In particular, does performing the Hajj pilgrimage to Mecca affect the views of pilgrims? David Clingingsmith, Asim Ijaz Khwaja, and Michael Kremer (2009) analyze this question by using two-stage least squares to compare successful and unsuccessful applicants in a lottery used by Pakistan to allocate Hajj visas. We will conduct pared-down models. The paper creates indices and implements additional statistical procedures to produce a broader and clearer picture. It is not a bad idea to read this paper to see how we can extend the methods we learn in class to your own work. I posted the paper on Canvas for your convenience. Data description Variable Description hajj2006 Went on Hajj trip in 2006 success Won the lottery to have expenses covered for Hajj ptygrp Categorical variable indicating size of party for Hajj trip smallpty 1 if small party group, 0 otherwise urban 1 if live in urban area, 0 otherwise age Age female 1 if female, 0 otherwise literate 1 if literate, 0 otherwise x_s7q10 Natl affairs: How often do you follow national affairs in the news on television or on the radio? Binary: 0=Twice a week or less, 1=Several times a week or more x_s14aq10 Religious: Do others regard you as religious? Binary: 1=Religious, 0=Not Religious x_s10bq4 OssamaIncorrect: Do you believe goals Ossama is fighting for are correct? Binary: 1=Not Correct at All/Slightly Incorrect, 0=Correct/Absolutely Correct x_s7q12a GovtForce: Govt should force people to conform to Islamic injunctions. Binary: 1=Agree Strongly/Agree, 0=Neutral/Disagree/Strongly Disagree x_s7q1 NatlInterest How interested would you say you are in national affairs? Binary: 0=Not interested, 1=Interested x_s3q3 Happy: how happy are you? From 1 (not at all happy) to 4 (very happy). x_s10eq2 GirlsSchool: In your opinion, girls should attend school. Binary: 0=Disagree, 1=Agree s10dq1 JobsWomen: When jobs are scarce, men should always have more right to a job than women. Binary: 0=Generally agree, 1=Generally Disagree More details on these and other variables are available in Appendix 3 of the paper. If you cannot access the version, the SSRN version works as well. 4.1 Estimate a basic OLS model with “Do others regard you as religious” as the dependent variable as a function of Hajj2006. Explain how there might be endogeneity. hajj_public %&gt;% lm(x_s14aq10~hajj2006, data=.) %&gt;% broom::tidy() ## # A tibble: 2 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.767 0.0154 49.8 4.94e-323 ## 2 hajj2006 0.0851 0.0199 4.27 2.09e- 5 There may be endogeneity due to baseline bias caused by the religiosity of respondents. A more religious respondent may be more likely to go on a Hajj trip and be classified as religious by others. Going to church, like actually being religious, is also a factor that may be correlated with x and lurking in the error term. 4.2 Explain how the “success” variable may satisfy the conditions for a instrumental variable. The two conditions, inclusion and exclusion, are: \\[Cov(X,Z)\\ne0\\] &amp; \\[Cov(Z,\\epsilon)=0\\] The lottery is randomizes, which means it is not correlated with the error term, or anything else other than the treatment variable, in our model. Further, it meaningfully effects our key independent which is tested below. 4.3 Estimate a 2SLS model Religious as a function of Hajj2006. ## With library(ivreg) hajj_public %&gt;% ivreg(x_s14aq10~hajj2006 | success, data=.) %&gt;% broom::tidy() ## # A tibble: 2 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.757 0.0169 44.9 1.09e-281 ## 2 hajj2006 0.101 0.0231 4.40 1.18e- 5 4.4 Show the first stage from the 2SLS model above. Explain the implications of the results. hajj_public %&gt;% lm(hajj2006~success, data=.) %&gt;% broom::tidy() ## # A tibble: 2 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.137 0.00893 15.4 6.35e-50 ## 2 success 0.854 0.0122 69.9 0 The t-score is 69.8663143 which is much higher than the 3 threshold. Our instrument meets in the inclusion condition. 4.5 Add covariates for age, literacy, urban, group size and gender to the 2SLS model Religious as a function of Hajj2006. What is different? Which variables are included in the first stage? hajj_public %&gt;% ivreg(x_s14aq10~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data=.) ## ## Call: ## ivreg(formula = x_s14aq10 ~ hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data = .) ## ## Coefficients: ## (Intercept) hajj2006 age literate ptygrp female urban ## 0.4934864 0.1012173 0.0026874 0.0146344 -0.0009545 0.1316934 0.0673979 4.6 Run multiple 2SLS models with OssamaIncorrect, GovtForce, NatlInterest, Happy, GirlsSchool and JobsWomen variables as dependent variables. Use the list of covariates from earlier. If you want, try using a loop or lapply (but not necessary). ## OssamaIncorrect hajj_public %&gt;% ivreg(x_s10bq4~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data=.) %&gt;% broom::tidy() ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.158 0.0682 2.32 0.0207 ## 2 hajj2006 0.0576 0.0247 2.33 0.0198 ## 3 age -0.00160 0.000844 -1.89 0.0585 ## 4 literate -0.00122 0.0283 -0.0430 0.966 ## 5 ptygrp -0.0151 0.00729 -2.08 0.0381 ## 6 female 0.0486 0.0240 2.03 0.0431 ## 7 urban 0.00542 0.0252 0.215 0.830 ## GovtForce hajj_public %&gt;% ivreg(x_s7q12a~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data=.) %&gt;% broom::tidy() ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.941 0.0487 19.3 2.04e-74 ## 2 hajj2006 -0.0308 0.0176 -1.75 8.08e- 2 ## 3 age 0.000518 0.000626 0.827 4.08e- 1 ## 4 literate -0.0255 0.0186 -1.37 1.70e- 1 ## 5 ptygrp -0.00846 0.00499 -1.69 9.05e- 2 ## 6 female -0.0228 0.0170 -1.34 1.80e- 1 ## 7 urban 0.000708 0.0168 0.0423 9.66e- 1 ## NatlInterest hajj_public %&gt;% ivreg(x_s7q1~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data=.) %&gt;% broom::tidy() ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.304 0.0783 3.88 1.11e- 4 ## 2 hajj2006 0.0155 0.0283 0.545 5.86e- 1 ## 3 age -0.000378 0.000999 -0.379 7.05e- 1 ## 4 literate 0.212 0.0300 7.05 2.80e-12 ## 5 ptygrp -0.00736 0.00802 -0.918 3.59e- 1 ## 6 female -0.117 0.0273 -4.30 1.84e- 5 ## 7 urban 0.0897 0.0267 3.36 8.01e- 4 ## Happy hajj_public %&gt;% ivreg(x_s3q3~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban, data=.) %&gt;% broom::tidy() ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 3.51 0.110 32.0 6.34e-174 ## 2 hajj2006 -0.0641 0.0396 -1.62 1.06e- 1 ## 3 age -0.00344 0.00140 -2.45 1.44e- 2 ## 4 literate 0.145 0.0420 3.45 5.81e- 4 ## 5 ptygrp 0.00463 0.0112 0.415 6.78e- 1 ## 6 female -0.0673 0.0383 -1.76 7.89e- 2 ## 7 urban 0.0169 0.0372 0.454 6.50e- 1 ## Girl School hajj_public %&gt;% ivreg(x_s10eq2~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female, data=.) %&gt;% broom::tidy() ## Warning in ivreg.fit(X, Y, Z, weights, offset, method, ...): more regressors than instruments ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.894 0.0355 25.2 4.07e-118 ## 2 hajj2006 0.0271 0.0133 2.04 4.16e- 2 ## 3 age 0.000258 0.000469 0.550 5.83e- 1 ## 4 literate 0.0414 0.0140 2.96 3.10e- 3 ## 5 ptygrp -0.00283 0.00373 -0.758 4.49e- 1 ## 6 female 0.00569 0.0128 0.443 6.58e- 1 ## 7 urban NA NA NA NA ## Jobs Women hajj_public %&gt;% ivreg(x_s10dq1~hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female, data=.) %&gt;% broom::tidy() ## Warning in ivreg.fit(X, Y, Z, weights, offset, method, ...): more regressors than instruments ## # A tibble: 7 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.153 0.0493 3.10 0.00194 ## 2 hajj2006 -0.00687 0.0185 -0.371 0.711 ## 3 age -0.00104 0.000651 -1.59 0.112 ## 4 literate 0.0241 0.0194 1.24 0.215 ## 5 ptygrp -0.00932 0.00519 -1.80 0.0724 ## 6 female 0.0569 0.0179 3.18 0.00148 ## 7 urban NA NA NA NA ## Loop ## DVs dvs &lt;- c(&quot;hajj_public$x_s10bq4&quot;, &quot;hajj_public$x_s7q12a&quot;, &quot;hajj_public$x_s7q1&quot;, &quot;hajj_public$x_s3q3&quot;, &quot;hajj_public$x_s10eq2&quot;, &quot;hajj_public$x_s10dq1&quot;) ## Loop for(i in 1:length(dvs)){ model &lt;- paste(&quot;model&quot;,i, sep=&quot;&quot;) m &lt;- ivreg(as.formula(paste(dvs[i],&quot;~ hajj2006 + age + literate + ptygrp + female + urban | success + age + literate + ptygrp + female + urban&quot;)), data = hajj_public) assign(model,m)} model_list &lt;- list(model1, model2, model3, model4, model5, model6) b &lt;- round(sapply(model_list, function(x) x$coefficients[&quot;hajj2006&quot;]) , 2) t &lt;- round(sapply(model_list, function(x) { summary(x)$coefficients[&quot;hajj2006&quot;, 3]}) , 2) names &lt;- c(&quot;OsamaIncorrect&quot;, &quot;GovtForce&quot;, &quot;NatlInterest&quot;, &quot;Happy&quot;, &quot;GirlsSchool&quot;, &quot;JobsWomen&quot;) results &lt;- data.frame(DV = names, b, t) %&gt;% arrange(desc(b)) results ## DV b t ## 1 OsamaIncorrect 0.06 2.33 ## 2 GirlsSchool 0.03 1.99 ## 3 NatlInterest 0.02 0.55 ## 4 JobsWomen -0.01 -0.44 ## 5 GovtForce -0.03 -1.75 ## 6 Happy -0.06 -1.62 "]]
